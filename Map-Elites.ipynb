{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fzxz7A8wCeZh"
   },
   "source": [
    "##### GPU Check\n",
    "-----\n",
    "Check if GPUs are being used, we have already installed tensroflow for GPU in our conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "print(len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9W1mHM7YFnqQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import configparser\n",
    "from yellowbrick.text import FreqDistVisualizer\n",
    "import time\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GA import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import base, creator, tools, algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read config file\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_parser = configparser.ConfigParser()\n",
    "config_parser.read_file(open('./Config.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config_var(experiment_name, var):\n",
    "    return config_parser.get(experiment_name, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_distribution():\n",
    "    print('Counts of proteins:\\n',corona_seq.groupby('class').size())\n",
    "    print('\\nPercentage of the distribution of labelled records:')\n",
    "    print(round(corona_seq.groupby('class').size()/corona_seq.shape[0]*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_shape(train_s, test_s, ytrain_s, ytest_s, y_test):\n",
    "    print('\\n')\n",
    "    print('Data shape - Train, Test:',train_s,',',test_s)\n",
    "    print('Label shape - Train, Test:',ytrain_s,',',ytest_s)\n",
    "    print('\\n')\n",
    "    counter = collections.Counter(y_test)\n",
    "    counter.most_common()\n",
    "    print('Test Label values and counts:\\n',sorted(counter.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_train_test_data():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(corona_seq['joined_words'],\n",
    "                                                        y_corona, \n",
    "                                                        shuffle = True,test_size = 0.25, \n",
    "                                                        random_state=0, stratify=y_corona)\n",
    "\n",
    "    X_train = cv.fit_transform(X_train)\n",
    "    X_test = cv.transform(X_test)\n",
    "\n",
    "    X_train = get_array_from_sparsematrix(X_train)\n",
    "    X_test = get_array_from_sparsematrix(X_test)\n",
    "\n",
    "    train_s = X_train.shape\n",
    "    test_s = X_test.shape\n",
    "    ytrain_s = y_train.shape\n",
    "    ytest_s = y_test.shape\n",
    "\n",
    "    print_data_shape(train_s, test_s, ytrain_s, ytest_s, y_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_word_frequencies():\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.rc('xtick', labelsize=20) \n",
    "    features = cv.get_feature_names()\n",
    "    visualizer = FreqDistVisualizer(features=features, orient='v')\n",
    "    visualizer.fit(X_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array_from_sparsematrix(sparsematrix):\n",
    "    ret_array = sparsematrix.todense()\n",
    "    return ret_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clfMultinomialNB(X_train, X_test, y_train, y_test):\n",
    "    start = time.time()\n",
    "    print ('\\n\\nAlgorithm Name: MultinomialNB')\n",
    "    print('___________________________________________________________________\\n')\n",
    "    print('\\ntraining model.........')\n",
    "    clf = MultinomialNB(alpha=0.1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print('\\ntesting.........\\n')\n",
    "    y_pred = predict(clf,X_test)\n",
    "    print_metrices(y_test, y_pred)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(classifier, testdata, dense =False):\n",
    "    if dense:\n",
    "        testdata = testdata.todense()\n",
    "    return classifier.predict(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension_reduction_pca(X_train, X_test,no_of_components=9):\n",
    "    pca = PCA(n_components=9)\n",
    "    \n",
    "    X_pca_train = pca.fit_transform(X_train)\n",
    "    X_pca_test = pca.transform(X_test)\n",
    "\n",
    "    # Output PCA variance results\n",
    "    #print(\"Singular values = \\n\",pca.singular_values_)  # Not required to print\n",
    "    print(\"\\nProportion of variance = \\n\",pca.explained_variance_ratio_) # Required to print\n",
    "    print(\"\\nTotal of variance covered  = \\n\",round(sum(pca.explained_variance_ratio_),2)*100, \"%\")\n",
    "\n",
    "    scaler, X_scaled_train = minmaxscaler_fit_transform(X_pca_train)\n",
    "    X_scaled_test = minmaxscaler_transform(scaler, X_pca_test)\n",
    "    return X_scaled_train, X_scaled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmaxscaler_fit_transform(array_object):\n",
    "  scaler = MinMaxScaler()\n",
    "  return scaler, scaler.fit_transform(array_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmaxscaler_transform(scaler, array_object):\n",
    "  return scaler.transform(array_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_test, y_predicted):\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    precision = precision_score(y_test, y_predicted, average='weighted', zero_division=0.0)\n",
    "    recall = recall_score(y_test, y_predicted, average='weighted', zero_division=0.0)\n",
    "    f1 = f1_score(y_test, y_predicted, average='weighted')\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_header():\n",
    "    print('___________________________________________________________________\\n')\n",
    "    experiment_info = get_config_var('Jupyter Experiment', 'name')\n",
    "    min_ngram = get_config_var('Jupyter Experiment', 'min_ngram')\n",
    "    max_ngram = get_config_var('Jupyter Experiment', 'max_ngram')\n",
    "    kmersize =get_config_var('Jupyter Experiment', 'kmersize')\n",
    "    dim_reduction_type = get_config_var('Jupyter Experiment', 'dim_reduction_type')\n",
    "    \n",
    "    print('Experiment Information:', experiment_info,' with ',dim_reduction_type,'\\n')\n",
    "    print('___________________________________________________________________\\n')\n",
    "    print('Pre-processing - kmer size:', kmersize)\n",
    "    print('Pre-processing - min_ngram and max_ngram:',min_ngram,',',max_ngram)\n",
    "    print('dim_reduction_type:',dim_reduction_type)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusionmatrix(y_test, y_pred):\n",
    "    print(\"\\nConfusion matrix:\\n\")\n",
    "    print(pd.crosstab(pd.Series(y_test, name='Actual'), pd.Series(y_pred, name='Predicted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy_precision_recall(y_test, y_pred):\n",
    "    accuracy, precision, recall, f1 = get_metrics(y_test, y_pred)\n",
    "    print(\"accuracy\\t= %.6f \\nprecision\\t= %.6f \\nrecall\\t\\t= %.6f \\nf1\\t\\t= %.6f\" % (accuracy, precision, recall, f1))  \n",
    "    #return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrices(y_test, y_pred):\n",
    "    print_header()\n",
    "    print('\\n___________________________________________________________________')\n",
    "    print(\"Results as below:\") \n",
    "    print('___________________________________________________________________\\n')\n",
    "    print_confusionmatrix(y_test, y_pred)\n",
    "    print(\"\\nMatrices:\\n\")\n",
    "    print_accuracy_precision_recall(y_test, y_pred)\n",
    "    end = time.time()\n",
    "    print('___________________________________________________________________')\n",
    "    print('\\nElapsed Time:', (end - start)/60)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZu2wgbE6qh4"
   },
   "source": [
    "##### Prepare data\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "restore pickle object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./source/corona_seq.pkl','rb') as pickle_file:\n",
    "  corona_seq = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_seq = corona_seq.sample(frac=1,random_state=4).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of proteins:\n",
      " class\n",
      "envelope protein                509\n",
      "membrane glycoprotein           413\n",
      "nucleocapsid phosphoprotein    1108\n",
      "orf10 protein                    83\n",
      "orf3 protein                    711\n",
      "orf6 protein                    178\n",
      "orf7a protein                   406\n",
      "orf7b protein                   223\n",
      "orf8 protein                    300\n",
      "spike glycoprotein             2019\n",
      "dtype: int64\n",
      "\n",
      "Percentage of the distribution of labelled records:\n",
      "class\n",
      "envelope protein                8.55\n",
      "membrane glycoprotein           6.94\n",
      "nucleocapsid phosphoprotein    18.62\n",
      "orf10 protein                   1.39\n",
      "orf3 protein                   11.95\n",
      "orf6 protein                    2.99\n",
      "orf7a protein                   6.82\n",
      "orf7b protein                   3.75\n",
      "orf8 protein                    5.04\n",
      "spike glycoprotein             33.93\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "**Balance the data**\n",
    "\n",
    "1. Downsample high frequency classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for protein_name in ['nucleocapsid phosphoprotein', 'spike glycoprotein', 'orf3 protein']:\n",
    "  # Separate majority and minority classes\n",
    "  df_majority = corona_seq.loc[corona_seq['class'] == protein_name]\n",
    "  df_minority = corona_seq.loc[corona_seq['class'] != protein_name]\n",
    "\n",
    "  # Downsample majority class\n",
    "  df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=500,    # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    "  # Concatenate both dataframes again\n",
    "  corona_seq =  pd.concat([df_majority_downsampled, df_minority])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Upsample low frequency classes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for protein_name in ['membrane glycoprotein', 'orf8 protein', 'orf7a protein', 'orf7b protein', 'orf6 protein','orf10 protein']:\n",
    "  # Separate majority and minority classes\n",
    "  df_majority = corona_seq.loc[corona_seq['class'] != protein_name]\n",
    "  df_minority = corona_seq.loc[corona_seq['class'] == protein_name]\n",
    "\n",
    "  # Downsample majority class\n",
    "  df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,    # sample without replacement\n",
    "                                 n_samples=500,     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    "  # Concatenate both dataframes again\n",
    "  corona_seq =  pd.concat([df_minority_upsampled, df_majority])\n",
    "\n",
    "  corona_seq = corona_seq.sample(frac=1,random_state=4).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of proteins:\n",
      " class\n",
      "envelope protein               509\n",
      "membrane glycoprotein          500\n",
      "nucleocapsid phosphoprotein    500\n",
      "orf10 protein                  500\n",
      "orf3 protein                   500\n",
      "orf6 protein                   500\n",
      "orf7a protein                  500\n",
      "orf7b protein                  500\n",
      "orf8 protein                   500\n",
      "spike glycoprotein             500\n",
      "dtype: int64\n",
      "\n",
      "Percentage of the distribution of labelled records:\n",
      "class\n",
      "envelope protein               10.16\n",
      "membrane glycoprotein           9.98\n",
      "nucleocapsid phosphoprotein     9.98\n",
      "orf10 protein                   9.98\n",
      "orf3 protein                    9.98\n",
      "orf6 protein                    9.98\n",
      "orf7a protein                   9.98\n",
      "orf7b protein                   9.98\n",
      "orf8 protein                    9.98\n",
      "spike glycoprotein              9.98\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "Separate labels, encode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_corona = corona_seq.iloc[:, 1].values # y_corona for corona_seq\n",
    "#Encode labels\n",
    "labelencoder = LabelEncoder()\n",
    "y_corona = labelencoder.fit_transform(y_corona)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'envelope protein',\n",
       " 1: 'membrane glycoprotein',\n",
       " 2: 'nucleocapsid phosphoprotein',\n",
       " 3: 'orf10 protein',\n",
       " 4: 'orf3 protein',\n",
       " 5: 'orf6 protein',\n",
       " 6: 'orf7a protein',\n",
       " 7: 'orf7b protein',\n",
       " 8: 'orf8 protein',\n",
       " 9: 'spike glycoprotein'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_dict = dict(zip(labelencoder.transform(labelencoder.classes_), labelencoder.classes_))\n",
    "#Check dictionary\n",
    "le_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Join words with an empty space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_seq['joined_words'] = list(corona_seq['words'])\n",
    "for item in range(len(corona_seq['joined_words'])):\n",
    "   corona_seq['joined_words'][item] = ' '.join([word for word in corona_seq['joined_words'][item] if word not in ['nnnnnn']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    atggat tggatt ggattt gatttg atttgt tttgtt ttgt...\n",
       "1    atrggc trggct rggcta ggctat gctata ctatat tata...\n",
       "2    atggat tggatt ggattt gatttg atttgt tttgtt ttgt...\n",
       "3    atgttt tgtttg gtttgt tttgtt ttgttt tgtttt gttt...\n",
       "4    gttcta ttctaa tctaaa ctaaat taaatc aaatca aatc...\n",
       "Name: joined_words, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corona_seq['joined_words'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Count vectorizer - similar to bag-of-words - only thing is we do not have distinct vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(int(get_config_var('Jupyter Experiment', 'min_ngram')),int(get_config_var('Jupyter Experiment', 'max_ngram'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Split the data for training and testing, check their sizes and class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Data shape - Train, Test: (3756, 11984) , (1253, 11984)\n",
      "Label shape - Train, Test: (3756,) , (1253,)\n",
      "\n",
      "\n",
      "Test Label values and counts:\n",
      " [(0, 128), (1, 125), (2, 125), (3, 125), (4, 125), (5, 125), (6, 125), (7, 125), (8, 125), (9, 125)]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_cv_train_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "If dimension reduction method is PCA, apply PCA get 9 components, scale the data with min max scaler. Later train the model of type \n",
    "Multi-Nomial Naive Bayes Algorithm and test. Print the results.\n",
    "\n",
    "If dimension reduction method is Map-Elites, reduce dimensions with Map-Elites evalutionary approach and print the solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Proportion of variance = \n",
      " [0.62774528 0.10387606 0.0621773  0.0510527  0.04284345 0.02457202\n",
      " 0.01868454 0.00924098 0.00665491]\n",
      "\n",
      "Total of variance covered  = \n",
      " 95.0 %\n",
      "\n",
      "\n",
      "Algorithm Name: MultinomialNB\n",
      "___________________________________________________________________\n",
      "\n",
      "\n",
      "training model.........\n",
      "\n",
      "testing.........\n",
      "\n",
      "___________________________________________________________________\n",
      "\n",
      "Experiment Information: Feature Reduction  with  PCA \n",
      "\n",
      "___________________________________________________________________\n",
      "\n",
      "Pre-processing - kmer size: 6\n",
      "Pre-processing - min_ngram and max_ngram: 1 , 1\n",
      "dim_reduction_type: PCA\n",
      "\n",
      "___________________________________________________________________\n",
      "Results as below:\n",
      "___________________________________________________________________\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "Predicted    0    1    2    3    4    5    6    7    8    9\n",
      "Actual                                                     \n",
      "0          128    0    0    0    0    0    0    0    0    0\n",
      "1            0  125    0    0    0    0    0    0    0    0\n",
      "2            0    0  125    0    0    0    0    0    0    0\n",
      "3            0    0    0  125    0    0    0    0    0    0\n",
      "4            0    0    0    0  125    0    0    0    0    0\n",
      "5            0    0    0    0    0  125    0    0    0    0\n",
      "6            0    0    0    0    0    0  125    0    0    0\n",
      "7            0    0    0    0    0    0    0  125    0    0\n",
      "8            0    0    0    0    0    0    0    0  125    0\n",
      "9            0    0    0    0    0    0    0    0    0  125\n",
      "\n",
      "Matrices:\n",
      "\n",
      "accuracy\t= 1.000000 \n",
      "precision\t= 1.000000 \n",
      "recall\t\t= 1.000000 \n",
      "f1\t\t= 1.000000\n",
      "___________________________________________________________________\n",
      "\n",
      "Elapsed Time: 0.026540664831797282\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if get_config_var('Jupyter Experiment', 'dim_reduction_type') == 'PCA':\n",
    "    xtrn, xtst = dimension_reduction_pca(X_train, X_test,9)\n",
    "    start = time.time()\n",
    "    clf = clfMultinomialNB(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_generations = int(get_config_var('GA Setup', 'no_generations'))\n",
    "no_individuals = int(get_config_var('GA Setup', 'no_individuals'))\n",
    "crossover_rate = float(get_config_var('GA Setup', 'crossover_rate'))\n",
    "mutation_rate = float(get_config_var('GA Setup', 'mutation_rate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateES(ind_cls, strg_cls, size):\n",
    "    #print('generateES1',ind_cls, strg_cls, size)\n",
    "    ind = ind_cls(random.randint(0,X_train.shape[1]-1) for _ in range(size))\n",
    "    #print('generateES2',ind)\n",
    "    ind.strategy = strg_cls(random.randint(0,X_train.shape[1]-1) for _ in range(size))\n",
    "    #print('generateES3',ind.strategy)\n",
    "    return ind\n",
    "\n",
    "def selElitistAndTournament(individuals, k, frac_elitist, tournsize):\n",
    "    return tools.selBest(individuals, int(k*frac_elitist)) + tools.selTournament(individuals, int(k*(1-frac_elitist)), tournsize=tournsize)\n",
    "\n",
    "def get_data_using_indexes(binary_featureindices):\n",
    "    X_trn = X_train[:,binary_featureindices]\n",
    "    X_tst = X_test[:,binary_featureindices]\n",
    "    return X_trn, X_tst\n",
    "\n",
    "def eval_model_function(individual):\n",
    "    #print(f'GA-Individual: {individual}')\n",
    "    X_trn, X_tst = get_data_using_indexes(individual)\n",
    "    \n",
    "    clf = MultinomialNB(alpha=0.1)\n",
    "    clf.fit(X_trn, y_train)\n",
    "    y_pred = predict(clf,X_tst)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    fitness = accuracy\n",
    "    \n",
    "    #print(f'GA-fitness from Eval function:{fitness}')\n",
    "    return fitness,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ichec/home/users/i18205615/.conda/envs/18205615/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "/ichec/home/users/i18205615/.conda/envs/18205615/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "/ichec/home/users/i18205615/.conda/envs/18205615/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Strategy' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dimension (3756, 11984)\n",
      "Reduced dimension (3756, 10)\n",
      "Accuracy with with lowest scoring featureset 84.19792498004789\n",
      "Accuracy with with top scoring (optimized) featureset 94.33359936153232\n"
     ]
    }
   ],
   "source": [
    "creator.create('FitnessMax', base.Fitness, weights=(1.0,))\n",
    "creator.create('Individual', list, typecode=\"I\", fitness=creator.FitnessMax, strategy=None)\n",
    "creator.create(\"Strategy\", list, typecode=\"I\")\n",
    "\n",
    "individual_size = (int(get_config_var('GA Setup', 'featureset_size')))\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# generation functions\n",
    "toolbox.register(\"individual\", generateES, creator.Individual, creator.Strategy, individual_size)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "\n",
    "toolbox.register(\"select\", selElitistAndTournament, frac_elitist=0.1 , tournsize=3)\n",
    "\n",
    "toolbox.register(\"evaluate\", eval_model_function)\n",
    "\n",
    "# initialize parameters\n",
    "pop = toolbox.population(n=no_individuals)\n",
    "hof = tools.HallOfFame(no_individuals * no_generations)\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)\n",
    "stats.register(\"std\", np.std)\n",
    "\n",
    "# genetic algorithm\n",
    "pop, logbook = algorithms.eaSimple(pop, toolbox, cxpb=crossover_rate, mutpb=mutation_rate,ngen=no_generations, stats=stats, halloffame=hof,verbose=False)\n",
    "\n",
    "#print('GA-Logbook:', logbook)\n",
    "#print('GA-Best possible candidates:')\n",
    "\n",
    "#cnt=0\n",
    "#for top in hof.items:\n",
    "#    cnt = cnt+1\n",
    "#    print(f'GA--Generation: {cnt}, Top featureset: {top}')\n",
    "\n",
    "print(\"Original dimension\",X_train.shape)\n",
    "print(\"Reduced dimension\",X_trn.shape)\n",
    "\n",
    "#Run with lowest scoring featureset\n",
    "X_trn, X_tst = get_data_using_indexes(hof.items[100])\n",
    "clf = MultinomialNB(alpha=0.1)\n",
    "clf.fit(X_trn, y_train)\n",
    "y_pred = predict(clf,X_tst)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy with with lowest scoring featureset', accuracy * 100)\n",
    "\n",
    "#Run with top scoring featureset\n",
    "X_trn, X_tst = get_data_using_indexes(hof.items[0])\n",
    "clf = MultinomialNB(alpha=0.1)\n",
    "clf.fit(X_trn, y_train)\n",
    "y_pred = predict(clf,X_tst)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy with with top scoring (optimized) featureset', accuracy * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "##### Map-Elites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "RNAClassification_Baseline_ichec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-18205615]",
   "language": "python",
   "name": "conda-env-.conda-18205615-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
